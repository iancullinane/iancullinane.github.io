---
title: Building a Nomad Cluster
subtitle: The engine behind our distributed system
tags: ops devops cloud docker
---

*Published for momentum, updates coming*

## Getting ready

In the next few posts I will be implementing and deploying a nomad cluster using the AWS CDK. Progress there should be evident in the Github Repository [iancullinane/pants-constructs](https://github.com/iancullinane/pants-constructs). This repo will hold the components and higher level constructs of our app. I will be using off-the-shelf containers for the nomad server and client inside the cluster.

If you want to follow along I will be doing my CDK in Typescript, and later implementing Drone, though I know GitHub actions are the HNT.

## Nomad by HashiCorp

[Nomad](https://www.nomadproject.io/) is open source cluster management software. It offers a bare bones "bring your own" philosophy, and is often used for container orchestration. You are probably thining "kubernetes..." at the mention of orchestration and you would be correct, Nomad competes in this space. Nomad is a different flavor of what k8s offers, and in my opinion, a far better choice. To this day I don't know how Kubernetes has become so popular. 

I won't get too deep into k8s/Nomad comparisons because I have no interest in talking about k8s. 

Nomad however is great. It offers simple clean API's, and you can serve it a variety of providers to connect to other existing tech. More on this in later posts. It "feels" more plug-n-play than the endless and arcane configurations of Kubernetes. It also plays nicely with the HashiCorp suite of products, which are all powerful. My only complaint is the use of their snowflake filetype `.hcl` ([link](https://www.nomadproject.io/docs/job-specification/hcl2)) but, I am sure they had their reasons. 

## Raft

Raft is a concensus algorithm. You can explore it visually [here](http://thesecretlivesofdata.com/raft/). The general idea hinges on a core cluster which implements a gossip protocol, keeping the cluster up-to-date via a election/leader/follower/vote system. When all members of a cluster agreem, write ahead logging is used to update each node.

On top of this, we will need to provide a service mesh. HashiCorp provides another product called Consul, but I am not sure if we will use it yet. Other options exist, such as [Traefik](https://traefik.io/). Veterans may also think of Etcd or Zookeeper, which were useful in their time, however I won't be using either. 
